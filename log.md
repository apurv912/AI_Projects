## Test 1 — <Company/Role> — <Date>
### JD
About the job
freshcells systems engineering GmbH is a software service provider based in Düsseldorf with a dynamic team of over 50 creative experts from various fields.


We focus on authenticity, individual talent development and open communication. We build on respect, trust and responsibility. As an innovation-driven company, we invest in new ideas. We know that the best results are achieved as a team. We make mistakes, but we learn from them. We are open and courageous for new ways.
Join us on our exciting journey in what is probably the most important and forward-looking area - software development - as a AI Specialist (m/f/d) in full-time hybrid or remote.
We hire people who want to understand how things work, not just how to wire them together.
You don’t have to know everything. But you should want to know why.
We’re seeking an Applied AI Project Manager (H/U/M/A/N) to lead AI initiatives. The role centers on scoping, planning, prioritizing, and delivering AI solutions that integrate into internal and external products and workflows. You have prior hands-on experience as a developer in the AI space and can go deep when needed, but your primary value is directing teams, aligning stakeholders, managing risks, timelines, and budgets, and ensuring high-quality delivery. You will coordinate engineers, designers, data specialists, and business owners, communicate clearly to technical and non-technical audiences, and own the roadmap and KPIs for AI features across on-prem and cloud environments.
What we offer you:



Flex-time for early birds and night owls

Flexible home office days

Company pension scheme with employer contribution

Subsidy for the Germany public transport ticket

Subsidy for Urban Sports Club

Benefits portal with offers from online shops and physical stores of various brands

A secure, long-term workplace

Regular feedback sessions, team meetings & retrospectives

Space for your own ideas and personal development

Digital training courses, freely available to all employees

Support with relocation processes, as well as free German courses for newcomers

Shared activities such as summer and winter parties, monthly company breakfasts, etc.

A dog-friendly work environment


Aufgaben

Own end-to-end delivery of AI initiatives: define scope, success metrics, milestones, and acceptance criteria

Create and maintain AI roadmaps and backlogs; run sprint planning, reviews, and cross-team coordination

Translate business needs into technical requirements and interface specifications for APIs, services, and integrations

Lead technical discovery and solution design for LLM, RAG, Vision, and generative use cases

Plan resources and budgets; sequence work, manage dependencies, and remove delivery blockers

Establish delivery quality: code review gates, CI/CD, monitoring, and post-launch KPIs

Oversee on-prem and cloud deployments, including security, data governance, and cost controls

Communicate status and risks clearly to stakeholders; produce concise docs and demos for decision-making

Drive knowledge transfer and enablement for developers and non-technical users of AI tools

Track model and platform changes and assess impact on existing solutions; manage upgrades and deprecations


Qualifikation

3+ years as a software/ML engineer building AI features or platforms, with shipped production use cases

2+ years leading AI projects or acting as a technical project/program manager

Proven delivery using AI and ability to review designs and guide technical trade-offs

Solid Python familiarity with frameworks such as AI-SDK, LangChain, LlamaIndex, or similar

Experience with web APIs, systems design basics, and networking fundamentals

Strong stakeholder management and communication skills for technical and non-technical audiences

Experience running agile and tools (e.g., Jira) and setting measurable product KPIs


Nice to have

Vendor evaluation and contract management for AI platforms or model providers

Background in on-prem/hybrid deployments, security reviews, and compliance

Public speaking, enablement sessions, or internal training on AI topics

### Highlights
 Improved overstock forecastaccuracy by about 30% (vs manual baseline) by introducing an Overstock Probability metric and embedding it into
weekly KPI cadence; reduced markdown rate by about 10% by enabling proactive vendor actions.
 Scaled adoption 4 to 30 stakeholders by launching QuickSight dashboards, recurring KPI digest to standardize overstock decisions across teams.
 Owned pilot discovery and scoping for GenAI + workflow automation use-cases by running stakeholder workshops, defining measurable success
metrics, prioritizing via impact vs effort (RICE-style), and building rapid low/no-code prototypes to secure buy-in and de-risk delivery.
 Shipped a GenAI + RAG deal-banner toolby evaluating 4-5 LLMs (quality/latency/cost) and adding retrieval + promptguardrails; cut build time
35-40 to 5-10 mins, reduced cost 40-50%, improved QA 65-70% to 80-85%, and scaled 1 to 5 brands and 3 to 30-40 users.
 Saved 30 mins/user/day by shippingworkflow automation for vendor email/receiptingestion into Quip/Sheets + end-of-day digest; scaled to 30-
40 users and reduced missed receipts/manual follow-ups.
### Output
1. Role Summary (max 3 lines): what this role really needs.
   Own end-to-end delivery of applied AI initiatives (LLM/RAG/Vision) from discovery → roadmap → production KPIs, across cloud + on-prem/hybrid.
   Translate business needs into technical requirements (APIs/integrations), run agile execution, and manage risks (security, cost, quality, upgrades).
   Be the “technical PM”: can go deep enough to review designs/trade-offs while aligning stakeholders at freshcells systems engineering GmbH (based in Düsseldorf).

2. ATS Keyword Pack:

* Hard skills/tools (10–15)
  Python, LLM evaluation (quality/latency/cost), RAG, prompt engineering, guardrails/safety, LangChain, LlamaIndex, API design (REST), integrations, system design basics, CI/CD, monitoring/observability, Jira, backlog management, cloud deployment (AWS/Azure/GCP).

* Domain/functional keywords (10–15)
  Applied AI delivery, GenAI features, LLM/RAG/Vision use-cases, technical discovery, scope & milestones, acceptance criteria, roadmap & prioritization, sprint planning/reviews, KPI definition & post-launch tracking, on-prem/hybrid deployments, security & data governance, cost controls/FinOps mindset, dependency management, model upgrades/deprecations, enablement/knowledge transfer.

* Soft skills (6–10)
  Stakeholder management, cross-functional leadership, crisp written communication, risk management, prioritization trade-offs, technical-to-nontechnical translation, ownership/accountability, structured problem solving.

3. Match Score (0–100) + 5 reasons.
   **81/100**

4. You’ve shipped production GenAI + RAG tooling with strong measurable outcomes (time, cost, QA, adoption).

5. Your work shows classic “AI project delivery” behaviors: discovery workshops, success metrics, prioritization, rapid prototyping.

6. Strong KPI/decision cadence experience (forecast accuracy, markdown reduction, weekly KPI rhythm).

7. Proven stakeholder scaling (4 → 30) via dashboards + standardized communication loops.

8. Biggest gaps are explicit on-prem/hybrid delivery, formal CI/CD + monitoring gates, and budget/resource planning ownership.

9. Gaps:

* Missing keywords (max 10)
  On-prem/hybrid deployment, CI/CD pipelines, code review gates, monitoring/alerting, security reviews, data governance/compliance, networking fundamentals, interface specifications, Jira (explicit), budget/resource planning.

* Missing experiences (max 5)

1. Leading/owning on-prem or hybrid AI deployments end-to-end.

2. Setting delivery quality bars (CI/CD, code review process, observability) as part of launch criteria.

3. Owning project budgets/vendor contracts (commercial + procurement).

4. Managing platform/model upgrades and deprecations with rollout plans.

5. Writing API/interface specs as a core deliverable (not just building internally).

6. Tailored Resume Bullets:

* Rewrite my highlights into 4 bullets in impact-first format.
* Keep each bullet <= 2 lines.

• **Improved overstock forecast accuracy ~30%** (vs manual baseline) by introducing an “Overstock Probability” metric and embedding it into weekly KPI cadence; **reduced markdown rate ~10%** via proactive vendor actions.
• **Scaled decision adoption 4 → 30 stakeholders** by launching KPI dashboards and a recurring performance digest, standardizing overstock actions across teams.
• **Cut GenAI banner build time 35–40 min → 5–10 min** by evaluating 4–5 LLMs (quality/latency/cost) and implementing RAG + prompt guardrails; **reduced cost 40–50%** and **improved QA 65–70% → 80–85%** while scaling **1 → 5 brands** and **3 → 30–40 users**.
• **Saved ~30 min/user/day** by automating vendor email + receipt ingestion into Quip/Sheets with end-of-day digests; scaled to **30–40 users** and reduced missed receipts/manual follow-ups.

6. Interview Ammo:

* 5 likely questions for this JD

1. Walk me through how you scope an AI initiative end-to-end (metrics, milestones, acceptance criteria, rollout).
2. How do you choose between LLMs/RAG approaches and make trade-offs on quality vs latency vs cost?
3. What are your “production readiness” checks for AI features (monitoring, CI/CD, quality gates, post-launch KPIs)?
4. How would you handle on-prem/hybrid constraints (security, data governance, cost controls) versus cloud?
5. Tell me about a time an AI solution underperformed—how did you debug, mitigate risk, and communicate to stakeholders?

* 1 strong story outline (Situation → Actions → Metrics → Result)
  **Situation:** Manual deal-banner creation was slow, costly, and inconsistent; teams needed a scalable, higher-quality GenAI workflow.
  **Actions:** Ran discovery with stakeholders → defined success metrics → evaluated 4–5 LLMs on quality/latency/cost → implemented RAG + guardrails → shipped and iterated with users; drove adoption across brands.
  **Metrics:** Build time **35–40 → 5–10 mins**, cost **↓40–50%**, QA **65–70% → 80–85%**, scale **1 → 5 brands** and **3 → 30–40 users**.
  **Result:** Delivered a production GenAI workflow with measurable ROI and a clear KPI loop—directly aligned with “applied AI project delivery + platform trade-offs” for this role.

Problem: Job applications need fast JD-to-resume alignment and ATS keyword coverage.

User: PM/TPM job seeker applying to multiple roles weekly.

Approach: Lightweight Streamlit app that generates a consistent, structured prompt using JD + candidate highlights.

Risks: Output quality depends on the model used; needs guardrails for hallucinations and keyword stuffing.

Next step: Add optional LLM API integration + “keyword diff” view + export to PDF.

